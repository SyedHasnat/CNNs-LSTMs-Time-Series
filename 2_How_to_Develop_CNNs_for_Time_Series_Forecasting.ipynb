{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SyedHasnat/CNNs-LSTMs-Time-Series/blob/main/2_How_to_Develop_CNNs_for_Time_Series_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2d3737f",
      "metadata": {
        "id": "a2d3737f"
      },
      "outputs": [],
      "source": [
        "from numpy import array,hstack\n",
        "import pandas as pd\n",
        "import matplotlib as pt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15bd4384",
      "metadata": {
        "id": "15bd4384"
      },
      "source": [
        "# Multivariate CNN Models Data pretaration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7e655a3",
      "metadata": {
        "id": "b7e655a3"
      },
      "source": [
        "## Multiple Input Series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10c396c6",
      "metadata": {
        "id": "10c396c6"
      },
      "outputs": [],
      "source": [
        "in_seq1=array([10,20,30,40,50,60,70,80,90])\n",
        "in_seq2=array([15,25,35,45,55,65,75,85,95])\n",
        "out_seq=array([in_seq1[i]+in_seq1[i] for i in range(len(in_seq1))])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aaf8432",
      "metadata": {
        "id": "5aaf8432",
        "outputId": "73d8b737-c985-4a0c-8bb3-a675b0bc0be7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[10],\n",
              "       [20],\n",
              "       [30],\n",
              "       [40],\n",
              "       [50],\n",
              "       [60],\n",
              "       [70],\n",
              "       [80],\n",
              "       [90]])"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "in_seq1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d43b5e5e",
      "metadata": {
        "id": "d43b5e5e"
      },
      "outputs": [],
      "source": [
        "in_seq1=in_seq1.reshape(len(in_seq1),1) #changing row to coumn\n",
        "in_seq2=in_seq2.reshape(len(in_seq2),1)\n",
        "out_seq=out_seq.reshape(len(out_seq),1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5040fc00",
      "metadata": {
        "id": "5040fc00"
      },
      "outputs": [],
      "source": [
        "#lets make a dataset \n",
        "dataset = hstack((in_seq1,in_seq2,out_seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40f36c3c",
      "metadata": {
        "id": "40f36c3c",
        "outputId": "1aadb6b6-6460-43d6-ae19-e79b0ccd8fc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 10  15  20]\n",
            " [ 20  25  40]\n",
            " [ 30  35  60]\n",
            " [ 40  45  80]\n",
            " [ 50  55 100]\n",
            " [ 60  65 120]\n",
            " [ 70  75 140]\n",
            " [ 80  85 160]\n",
            " [ 90  95 180]]\n"
          ]
        }
      ],
      "source": [
        "#for i in range(len(dataset)):\n",
        "#    print(dataset[i])\n",
        "#or\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6392b22f",
      "metadata": {
        "id": "6392b22f",
        "outputId": "4a6524f6-a388-4029-9edc-448aab5c3dcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9, 3)"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b3d1cb2",
      "metadata": {
        "id": "6b3d1cb2"
      },
      "source": [
        "# For CNN we need 3D lets reshape it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c352f918",
      "metadata": {
        "id": "c352f918"
      },
      "outputs": [],
      "source": [
        "dataset=dataset.reshape(dataset.shape[0],dataset.shape[1],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d50c4cab",
      "metadata": {
        "id": "d50c4cab",
        "outputId": "1fa80931-c007-4dc3-bb66-6a51318c7f8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9, 3, 1)"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "862f9bea",
      "metadata": {
        "id": "862f9bea"
      },
      "source": [
        "# Defining a fuction which will organize a data set for CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68181212",
      "metadata": {
        "id": "68181212",
        "outputId": "e5b39af4-6a95-46b7-cf3f-0c9f32ac2fb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7, 3, 2) (7,)\n",
            "[[10 15]\n",
            " [20 25]\n",
            " [30 35]] 65\n",
            "[[20 25]\n",
            " [30 35]\n",
            " [40 45]] 85\n",
            "[[30 35]\n",
            " [40 45]\n",
            " [50 55]] 105\n",
            "[[40 45]\n",
            " [50 55]\n",
            " [60 65]] 125\n",
            "[[50 55]\n",
            " [60 65]\n",
            " [70 75]] 145\n",
            "[[60 65]\n",
            " [70 75]\n",
            " [80 85]] 165\n",
            "[[70 75]\n",
            " [80 85]\n",
            " [90 95]] 185\n"
          ]
        }
      ],
      "source": [
        "#split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequences)):\n",
        "        # find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "        # check if we are beyond the dataset\n",
        "        if end_ix > len(sequences):\n",
        "            break\n",
        "        # gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return array(X), array(y)\n",
        "\n",
        "\n",
        "\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "print(X.shape, y.shape)\n",
        "# summarize the data\n",
        "for i in range(len(X)):\n",
        "    print(X[i], y[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b48f54d",
      "metadata": {
        "id": "2b48f54d"
      },
      "source": [
        "# Trying to explain the above code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26dfe504",
      "metadata": {
        "id": "26dfe504"
      },
      "outputs": [],
      "source": [
        "b=X[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2bad864",
      "metadata": {
        "id": "b2bad864",
        "outputId": "890ca1a9-2321-4c06-c6c1-943fbcbb304c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 2)"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b.shape# chapter 6 ki mong sara 3x1 wo oss 3x2 dai\n",
        "# da yo column ba mo 3 values warkra nu pa aghi na bad ba output wo oss 2 coulumns dy da aghi 3 , 3 warkao...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ebe10cd",
      "metadata": {
        "id": "1ebe10cd",
        "outputId": "db032c01-6846-425a-ade6-31c71b63fb60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[10 15]\n",
            " [20 25]\n",
            " [30 35]] 65\n",
            "[[20 25]\n",
            " [30 35]\n",
            " [40 45]] 85\n",
            "[[30 35]\n",
            " [40 45]\n",
            " [50 55]] 105\n",
            "[[40 45]\n",
            " [50 55]\n",
            " [60 65]] 125\n",
            "[[50 55]\n",
            " [60 65]\n",
            " [70 75]] 145\n",
            "[[60 65]\n",
            " [70 75]\n",
            " [80 85]] 165\n",
            "[[70 75]\n",
            " [80 85]\n",
            " [90 95]] 185\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X, y = list(), list()\n",
        "for i in range(len(dataset)):\n",
        "    # find the end of this pattern\n",
        "    end_ix = i +3\n",
        "    # check if we are beyond the dataset\n",
        "    if end_ix > len(dataset):\n",
        "        break\n",
        "# gather input and output parts of the pattern\n",
        "    #dataset[i:end_ix, :-1] matlab dataset[i na wakhli tar end_ix pori , :-1 except last column]\n",
        "    #dataset[end_ix-1, -1] matlab dataset[end_ix-1 matlb 3-1=2, -1 matlab total 3 columns dy -1=2.....matlab (2,2)]\n",
        "    \n",
        "    #seq_x, seq_y = dataset[i:end_ix, :-1], dataset[end_ix-1, -1] #-1 means don't store last column if -2 so last 2 columns\n",
        "    seq_x, seq_y = dataset[i:end_ix, :2], dataset[end_ix-1, 2]   #both are samw\n",
        "    X.append(seq_x)\n",
        "    y.append(seq_y)\n",
        "for i in range(len(X)):\n",
        "    print(X[i],y[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9046c3c",
      "metadata": {
        "id": "f9046c3c",
        "outputId": "f8313e82-7634-4329-eae0-328abd98d91a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 10,  15,  25],\n",
              "       [ 20,  25,  45],\n",
              "       [ 30,  35,  65],\n",
              "       [ 40,  45,  85],\n",
              "       [ 50,  55, 105],\n",
              "       [ 60,  65, 125],\n",
              "       [ 70,  75, 145],\n",
              "       [ 80,  85, 165],\n",
              "       [ 90,  95, 185]])"
            ]
          },
          "execution_count": 182,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "072f33d0",
      "metadata": {
        "id": "072f33d0"
      },
      "outputs": [],
      "source": [
        "seq1=([10,20,30,40,50,60,70,80,90])\n",
        "seq2=([15,25,35,45,55,65,75,85,95])\n",
        "seq3=([seq1[i]+seq2[i] for i in range(len(seq1))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ea2cf89",
      "metadata": {
        "id": "8ea2cf89"
      },
      "outputs": [],
      "source": [
        "seq1=array(seq1)\n",
        "seq2=array(seq2)\n",
        "seq3=array(seq3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1982ea7",
      "metadata": {
        "id": "f1982ea7"
      },
      "outputs": [],
      "source": [
        "seq1=seq1.reshape((len(seq1),1))\n",
        "seq2=seq2.reshape((len(seq2),1))\n",
        "seq3=seq3.reshape((len(seq3),1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ea02733",
      "metadata": {
        "id": "0ea02733"
      },
      "outputs": [],
      "source": [
        "dataset=hstack((seq1,seq2,seq3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "226f64e7",
      "metadata": {
        "id": "226f64e7",
        "outputId": "e3c83602-d465-4fa8-d7fe-201dbe2f2ea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[10 15]\n",
            " [20 25]\n",
            " [30 35]] 65\n",
            "[[20 25]\n",
            " [30 35]\n",
            " [40 45]] 85\n",
            "[[30 35]\n",
            " [40 45]\n",
            " [50 55]] 105\n",
            "[[40 45]\n",
            " [50 55]\n",
            " [60 65]] 125\n",
            "[[50 55]\n",
            " [60 65]\n",
            " [70 75]] 145\n",
            "[[60 65]\n",
            " [70 75]\n",
            " [80 85]] 165\n",
            "[[70 75]\n",
            " [80 85]\n",
            " [90 95]] 185\n"
          ]
        }
      ],
      "source": [
        "x,y=list(),list()\n",
        "for i in range(len(dataset)):\n",
        "    endx_i=i+3\n",
        "    if endx_i>len(dataset):\n",
        "        break\n",
        "    seq_x=dataset[i:endx_i,:2]\n",
        "    seq_y=dataset[endx_i-1,2]\n",
        "    x.append(seq_x)\n",
        "    y.append(seq_y)\n",
        "for i in range(len(x)):\n",
        "    print(x[i],y[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac44e529",
      "metadata": {
        "id": "ac44e529",
        "outputId": "cdf16e79-59ec-4477-ab1a-f1d6bd47a880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7, 3, 2)\n",
            "42\n"
          ]
        }
      ],
      "source": [
        "x=array(x)\n",
        "print(x.shape)\n",
        "print(x.size) #samples=7 time steps= 3 featutres= 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da4d6bca",
      "metadata": {
        "id": "da4d6bca"
      },
      "source": [
        "# Multivariate CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6489c546",
      "metadata": {
        "id": "6489c546",
        "outputId": "9844119e-c0c7-427b-f6ac-412ec56d3e90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 2)\n",
            "6\n",
            "(1, 3, 2)\n",
            "6\n",
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A16AD6D288> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[207.41014]]\n"
          ]
        }
      ],
      "source": [
        "# multivariate cnn example\n",
        "\n",
        "###################################################importing modules###############################################\n",
        "\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "\n",
        "###################################################function to split dataset#######################################\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(dataset, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(dataset)):\n",
        "        # find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "        # check if we are beyond the dataset\n",
        "        if end_ix > len(dataset):\n",
        "            break\n",
        "        # gather input and output parts of the pattern\n",
        "        seq_x, seq_y = dataset[i:end_ix, :-1], dataset[end_ix-1, -1]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return array(X), array(y)\n",
        "\n",
        "###################################################define input sequence###########################################\n",
        "\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "\n",
        "###################################################convert to [rows, columns] structure############################\n",
        "\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "\n",
        "###################################################horizontally stack columns#####################################\n",
        "\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "\n",
        "###################################################choose a number of time steps##################################\n",
        "\n",
        "n_steps = 3\n",
        "\n",
        "###################################################convert into input/output######################################\n",
        "\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "# the dataset knows the number of features, e. g. 2\n",
        "n_features = X.shape[2]\n",
        "\n",
        "###################################################define model##################################################\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=2, activation='relu' , input_shape=(n_steps,\n",
        "n_features)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, activation='relu' ))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam' , loss='mse' )\n",
        "\n",
        "###################################################fit model#####################################################\n",
        "\n",
        "model.fit(X, y, epochs=1000, verbose=0)\n",
        "\n",
        "###################################################demonstrate prediction########################################\n",
        "\n",
        "x_input = array([[80, 85], [90, 95], [100, 105]]) #input is 3x2 while in the previous chpater it ws 3x1\n",
        "print(x_input.shape)\n",
        "print(x_input.size)\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "print(x_input.shape)\n",
        "print(x_input.size)\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aea260c",
      "metadata": {
        "id": "6aea260c"
      },
      "source": [
        "# Multi-headed CNN Model\n",
        "There is another, more elaborate way to model the problem. Each input series can be handled by\n",
        "a separate CNN and the output of each of these submodels can be combined before a prediction\n",
        "is made for the output sequence. We can refer to this as a multi-headed CNN model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d86ce05",
      "metadata": {
        "id": "0d86ce05",
        "outputId": "857765d6-4147-471e-f90c-efcac17d746e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A16B1EF4C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[208.24243]]\n"
          ]
        }
      ],
      "source": [
        "# multivariate cnn example\n",
        "\n",
        "###################################################importing modules###############################################\n",
        "\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "###################################################function to split dataset#######################################\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(dataset, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(dataset)):\n",
        "        # find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "        # check if we are beyond the dataset\n",
        "        if end_ix > len(dataset):\n",
        "            break\n",
        "        # gather input and output parts of the pattern\n",
        "        seq_x, seq_y = dataset[i:end_ix, :-1], dataset[end_ix-1, -1]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return array(X), array(y)\n",
        "\n",
        "###################################################define input sequence###########################################\n",
        "\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "\n",
        "###################################################convert to [rows, columns] structure############################\n",
        "\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "\n",
        "###################################################horizontally stack columns#####################################\n",
        "\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "\n",
        "###################################################choose a number of time steps##################################\n",
        "\n",
        "# one time series per head\n",
        "n_features = 1\n",
        "\n",
        "###################################################separate input data############################################\n",
        "\n",
        "X1 = X[:, :, 0].reshape(X.shape[0], X.shape[1], n_features)\n",
        "X2 = X[:, :, 1].reshape(X.shape[0], X.shape[1], n_features)\n",
        "\n",
        "###################################################first input model##############################################\n",
        "\n",
        "visible1 = Input(shape=(n_steps, n_features))\n",
        "cnn1 = Conv1D(filters=64, kernel_size=2, activation='relu' )(visible1)\n",
        "cnn1 = MaxPooling1D(pool_size=2)(cnn1)\n",
        "cnn1 = Flatten()(cnn1)\n",
        "\n",
        "###################################################second input model############################################\n",
        "\n",
        "visible2 = Input(shape=(n_steps, n_features))\n",
        "cnn2 = Conv1D(filters=64, kernel_size=2, activation='relu' )(visible2)\n",
        "cnn2 = MaxPooling1D(pool_size=2)(cnn2)\n",
        "cnn2 = Flatten()(cnn2)\n",
        "\n",
        "###################################################merge input models############################################\n",
        "\n",
        "merge = concatenate([cnn1, cnn2])\n",
        "dense = Dense(50, activation='relu' )(merge)\n",
        "output = Dense(1)(dense)\n",
        "model = Model(inputs=[visible1, visible2], outputs=output)\n",
        "model. compile(optimizer='adam' , loss='mse' )\n",
        "\n",
        "###################################################fit model#####################################################\n",
        "\n",
        "model.fit([X1, X2], y, epochs=1000, verbose=0)\n",
        "\n",
        "###################################################fdemonstrate prediction#######################################\n",
        "\n",
        "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
        "x1 = x_input[:, 0].reshape((1, n_steps, n_features))\n",
        "x2 = x_input[:, 1].reshape((1, n_steps, n_features))\n",
        "yhat = model.predict([x1, x2], verbose=0)\n",
        "print(yhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80c57549",
      "metadata": {
        "id": "80c57549"
      },
      "source": [
        "# We may want to predict the value for each of the three time series for the next time step"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "761bf01c",
      "metadata": {
        "id": "761bf01c"
      },
      "source": [
        "# First we will prepare data to train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9937789f",
      "metadata": {
        "id": "9937789f",
        "outputId": "52fc0f54-9ac0-4184-ded9-4a862905a8ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6, 3, 3) (6, 3)\n",
            "[[10 15 25]\n",
            " [20 25 45]\n",
            " [30 35 65]] [40 45 85]\n",
            "[[20 25 45]\n",
            " [30 35 65]\n",
            " [40 45 85]] [ 50  55 105]\n",
            "[[ 30  35  65]\n",
            " [ 40  45  85]\n",
            " [ 50  55 105]] [ 60  65 125]\n",
            "[[ 40  45  85]\n",
            " [ 50  55 105]\n",
            " [ 60  65 125]] [ 70  75 145]\n",
            "[[ 50  55 105]\n",
            " [ 60  65 125]\n",
            " [ 70  75 145]] [ 80  85 165]\n",
            "[[ 60  65 125]\n",
            " [ 70  75 145]\n",
            " [ 80  85 165]] [ 90  95 185]\n"
          ]
        }
      ],
      "source": [
        "# multivariate cnn example\n",
        "\n",
        "###################################################importing modules###############################################\n",
        "\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "\n",
        "###################################################function to split dataset#######################################\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(dataset, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(dataset)):\n",
        "        # find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "        # check if we are beyond the dataset\n",
        "        if end_ix > len(dataset)-1:\n",
        "            break\n",
        "        # gather input and output parts of the pattern\n",
        "        seq_x, seq_y = dataset[i:end_ix, :], dataset[end_ix, :] # change #dataset[i:end_ix, :-1], dataset[end_ix-1, -1]\n",
        "        #dataset[i:end_ix, :] all columns \n",
        "        #dataset[end_ix, :] only 3rd row and all columns\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return array(X), array(y)\n",
        "\n",
        "###################################################define input sequence###########################################\n",
        "\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "\n",
        "###################################################convert to [rows, columns] structure############################\n",
        "\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "\n",
        "###################################################horizontally stack columns#####################################\n",
        "\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "\n",
        "###################################################choose a number of time steps##################################\n",
        "\n",
        "n_steps = 3\n",
        "\n",
        "###################################################convert into input/output######################################\n",
        "\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "# the dataset knows the number of features, e. g. 2\n",
        "print(X.shape, y.shape)\n",
        "# summarize the data\n",
        "for i in range(len(X)):\n",
        "    print(X[i], y[i])\n",
        "#n_features = X.shape[2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bb2a4d8",
      "metadata": {
        "id": "3bb2a4d8",
        "outputId": "367b698b-bf78-4191-835b-e95e28ae2af0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 3)\n",
            "9\n",
            "(1, 3, 3)\n",
            "9\n",
            "[[101.38163 106.30747 207.05624]]\n"
          ]
        }
      ],
      "source": [
        "# multivariate cnn example\n",
        "\n",
        "###################################################importing modules###############################################\n",
        "\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "\n",
        "###################################################function to split dataset#######################################\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(dataset, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(dataset)):\n",
        "        # find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "        # check if we are beyond the dataset\n",
        "        if end_ix > len(dataset)-1:\n",
        "            break\n",
        "        # gather input and output parts of the pattern\n",
        "        seq_x, seq_y = dataset[i:end_ix, :], dataset[end_ix, :] # change #dataset[i:end_ix, :-1], dataset[end_ix-1, -1]\n",
        "        #dataset[i:end_ix, :] all columns \n",
        "        #dataset[end_ix, :] only 3rd row and all columns\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return array(X), array(y)\n",
        "\n",
        "###################################################define input sequence###########################################\n",
        "\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "\n",
        "###################################################convert to [rows, columns] structure############################\n",
        "\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "\n",
        "###################################################horizontally stack columns#####################################\n",
        "\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "\n",
        "###################################################choose a number of time steps##################################\n",
        "\n",
        "n_steps = 3\n",
        "\n",
        "###################################################convert into input/output######################################\n",
        "\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "\n",
        "n_features = X.shape[2]\n",
        "\n",
        "###################################################define model##################################################\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=2, activation='relu' , input_shape=(n_steps,\n",
        "n_features)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, activation='relu' ))\n",
        "model.add(Dense(n_features))\n",
        "model. compile(optimizer='adam' , loss='mse' )\n",
        "\n",
        "###################################################fit model#####################################################\n",
        "\n",
        "model.fit(X, y, epochs=3000, verbose=0)\n",
        "\n",
        "###################################################demonstrate prediction#######################################\n",
        "\n",
        "x_input = array([[70,75,145], [80,85,165], [90,95,185]])\n",
        "print(x_input.shape)\n",
        "print(x_input.size)\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "print(x_input.shape)\n",
        "print(x_input.size)\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b9744b2",
      "metadata": {
        "id": "7b9744b2"
      },
      "source": [
        "# To be continue.....2.1"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Attachments",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "name": "2_How to Develop CNNs for Time Series Forecasting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}